{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it, you need to define 2 paths:\n",
    "- project_path (path to the folder name project_eval in git) **in line 3**\n",
    "- data_path (path to the data on your computer) **in line 11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading EEG eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib.util import spec_from_file_location, module_from_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_path = r'C:\\Users\\Antoine CHEHIRE\\IdeaProjects\\IFT6269_Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eeg_eval_path = os.path.join(project_path, 'Evaluation.py')\n",
    "predictor_path = os.path.join(project_path, 'Predictors.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spec = spec_from_file_location('EEG eval', eeg_eval_path)\n",
    "eeg_eval = module_from_spec(spec)\n",
    "spec.loader.exec_module(eeg_eval)\n",
    "\n",
    "spec = spec_from_file_location('Predictors', predictor_path)\n",
    "preds = module_from_spec(spec)\n",
    "spec.loader.exec_module(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RawData:\n",
    "    name = \"Raw data\"\n",
    "    \n",
    "    def generate_features(self, time_series):\n",
    "        \"\"\"\n",
    "        generate features from a time_series\n",
    "        :param np.ndarray time_series: nb_of_observations x nb_of_sensors matrix\n",
    "        :return np.ndarray feature_matrix: matrix of same shape\n",
    "        \"\"\"\n",
    "        # We do nothing as we want raw data\n",
    "        return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm = RawData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = preds.LogReg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to optimize parameters yet. It takes too long and doesn't improve results too much. So let's impose default sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.hyper_parameters_grid = {'C': [1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eeg = eeg_eval.EEGEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = r'D:\\Scolaire\\UdeM\\IFT_6269\\PROJECT\\data\\kaggle_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features...\n",
      "Scoring 1 out of 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antoine CHEHIRE\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Antoine CHEHIRE\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params obtained: {'C': 1}\n",
      "Scoring 2 out of 6...\n",
      "Best params obtained: {'C': 1}\n",
      "Scoring 3 out of 6...\n",
      "Best params obtained: {'C': 1}\n",
      "Scoring 4 out of 6...\n",
      "Best params obtained: {'C': 1}\n",
      "Scoring 5 out of 6...\n",
      "Best params obtained: {'C': 1}\n",
      "Scoring 6 out of 6...\n",
      "Best params obtained: {'C': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1391.637484550476"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time()\n",
    "eeg.evaluate(data_path, algorithm, pred, cv_fold=1, verbose=2)\n",
    "time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning means the classifier predicted only 0 as it yields better accuracy this way... So we may need to find a way to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo time</th>\n",
       "      <th>Accuracy 0</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Recall 0</th>\n",
       "      <th>F1-score 0</th>\n",
       "      <th>Accuracy 1</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recall 1</th>\n",
       "      <th>F1-score 1</th>\n",
       "      <th>Accuracy 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Recall 3</th>\n",
       "      <th>F1-score 3</th>\n",
       "      <th>Accuracy 4</th>\n",
       "      <th>Precision 4</th>\n",
       "      <th>Recall 4</th>\n",
       "      <th>F1-score 4</th>\n",
       "      <th>Accuracy 5</th>\n",
       "      <th>Precision 5</th>\n",
       "      <th>Recall 5</th>\n",
       "      <th>F1-score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw data - LogReg</th>\n",
       "      <td>10.9</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Algo time  Accuracy 0  Precision 0  Recall 0  F1-score 0  \\\n",
       "Raw data - LogReg       10.9       97.41          0.0       0.0         0.0   \n",
       "\n",
       "                   Accuracy 1  Precision 1  Recall 1  F1-score 1  Accuracy 2  \\\n",
       "Raw data - LogReg       97.41          0.0       0.0         0.0       97.41   \n",
       "\n",
       "                      ...      Recall 3  F1-score 3  Accuracy 4  Precision 4  \\\n",
       "Raw data - LogReg     ...           0.0         0.0       97.41          0.0   \n",
       "\n",
       "                   Recall 4  F1-score 4  Accuracy 5  Precision 5  Recall 5  \\\n",
       "Raw data - LogReg       0.0         0.0       97.41          0.0       0.0   \n",
       "\n",
       "                   F1-score 5  \n",
       "Raw data - LogReg         0.0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algo time is not nul since we need to load the data from the data path in memory which takes a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, there's an issue with the sparsity of the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the result is crucial as it makes it easier to make comparisons of different models without running the whole pipeline as it takes ages to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_save = os.path.join(project_path, 'Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = eeg.resultult.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eeg.save_json(os.path.join(path_to_save, file_name+'.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finer control (if necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the labels are not balanced, you may want to balance them manually to help the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = eeg.generate_features(data_path, algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may modify the features. Though please note that the score function needs y_train and y_test as a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus you still need to do as in the evaluation protocol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = features['y_train']\n",
    "y_test = features['y_test']\n",
    "\n",
    "# Let's say you want to see the scores for the 1st task:\n",
    "j = 0\n",
    "features['y_train'] = y_train[:, 0]\n",
    "features['y_test'] = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores, best_params = eeg.score_features(features, pred, cv_fold=1, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
